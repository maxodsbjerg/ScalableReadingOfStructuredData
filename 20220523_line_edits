# Easy to correct:
l. 52 -- 'This step suggests a chronological exploration of a dataset.' -- delete, it just repeats the header.

l. 66 -- add a small, inline explanation of what 'packages' are.

l. 88 -- 'The package in from the same group' -> 'The package [comes|is|was created by] from the same group...' [typo]

l. 120 -- add a comment to the code, explaining what the function parameters are

l. 124 -- 'according to different periods in art history to which are represented the most or the least' -- a little confusing, rephrase. Perhaps: '...according to different periods in art history, in order to establish which periods are more or less represented in the National Gallery dataset'

l. 195 -- 'beware' -> 'be aware'

l. 195 -- 'where we collected' -> 'when we collected'


l. 205 -- 'thus creating two lines for;' -> 'which creates two lines in the visualisation, one for...'

l. 209 -- in-line explanation of what 'aesthetics' are in this context

l.209 -- 'tells R, what the' -> 'tells R what the'

ll. 245-150 -- explanation of the pipe operator should really come in the first coding section, particularly as you note that 'once you get a hold of this idea the remainder of the data processing will be easier to read and understand'

l. 255 -- 'verfied' -> 'verified'

ll. 367-276 -- more detailed explanation of plot construction would be good

l. 382 -- 'two different kinds of distant readings' -> 'two different kinds of distant reading'

l. 384 -- 'reading individual tweet' -> 'reading individual tweets'

l. 397 -- First mention of R Markdown -- needs an explanation and a reasoning

l. 414 -- 'are variables that changes' -> 'are variables that change'

l. 540 -- 'the date of tweets is shown in a way, which is' -> 'the date of tweets is shown in a way which is'

# Needs discussion

l. 34 -- introduces the concept of scalable reading without explanation (only needs a small definition here, something like: ...scalable reading of structured data, a combination of close interpretation of individual texts and statistical analysis of the corpus)

#Lesson Aims before #Lesson Structure?

l. 46 -- 'The reproducible way of selecting...' good that you're introducing examples of disciplines that could use the method, but maybe also add something about its extendibility to others in the humanities.

l. 52 -- 'Had we worked on data from the National Gallery' -- rephrase, it implies a contradiction with what you said above (that it forms part of the discussion). I.e, 'In the case of the National Gallery data...'

l. 54 -- 'Had we worked on data from the National Gallery' -- rephrase

l. 56 -- 'Had we worked on data from the National Gallery' -- rephrase

#Data and Prerequisites: could not a third option be to offer a base dataset that users can get from PH to get started without having to follow other lessons?

#Data and Prerequisites: add another option, 'Using the rtweet package and your own twitter account, as described below'

l. 129 (and in the section more generally, and elsewhere in the tutorial) -- the subject changes midway through the sentence: you/we

ll. 164-167 -- the code should appear before the explanation, so that readers know what the explanation refers to. Somewhere between ll.142-143.

ll. 217-228 -- code should be before its explanation

ll 454-ff -- Why are we exporting the new dataset to a JSON file? i.e., why are we exporting it in the first place, and why specifically using JSON rather than a tabular format (csv, for example)? I still don't see a clear reasoning for it, though I might have missed it of course.

l. 496 -- 'how many likes you top-20 lies above' -> I don't really understand this sentence, there's a typo or something missing somewhere.

l.535 -- maybe add a note that fetching the twitter text for each url can also be automated using the API, though it is not covered in this tutorial


